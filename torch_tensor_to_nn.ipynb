{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT가 만들어준 Pytorch 예제 풀기 \n",
    "* __(텐서 생성~신경망 생성까지)__\n",
    "* GPT에게 Pytorch 학습 정도를 스스로 파악할 수 있도록, 예제를 제공해달라고 부탁하였으며,     \n",
    "해당 예제를 직접 풀고 부연 설명을 작성하였음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 1. 크기가 3x3인 랜덤 텐서를 생성하고 tensor1에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8880, 0.1203, 0.2687],\n",
      "        [0.5581, 0.4830, 0.7591],\n",
      "        [0.8923, 0.1407, 0.4744]])\n"
     ]
    }
   ],
   "source": [
    "tensor1=torch.rand(3,3)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 1-2. \n",
    "* 크기가 3x3인 1로 채워진 텐서를 생성하여 tensor2에 저장하고,    \n",
    "* tensor1과 tensor2를 더한 결과를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "plus result is: \n",
      "tensor([[1.8880, 1.1203, 1.2687],\n",
      "        [1.5581, 1.4830, 1.7591],\n",
      "        [1.8923, 1.1407, 1.4744]])\n"
     ]
    }
   ],
   "source": [
    "tensor2=torch.tensor([[1,1,1],[1,1,1],[1,1,1]]) #이렇게 작성해도 맞지만, 아래 방법이 더 간단함.\n",
    "tensor2=torch.ones(3,3) #(더 간단한 방법)\n",
    "print(tensor2)\n",
    "print(\"plus result is: \")\n",
    "print(tensor1+tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 1-3. 텐서 확장 및 축소 진행 후, 특정 차원에 접근하기\n",
    "* 2*3 크기의 텐서를 생성하고, 첫번째 축과 세번째 축에 차원을 추가 후 shape 확인\n",
    "* 크기가 1인 차원 제거\n",
    "* 첫번째 차원에 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==기존 텐서 출력==\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n",
      "==차원 추가 과정==\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "torch.Size([1, 2, 3])\n",
      "tensor([[[[1, 2, 3]],\n",
      "\n",
      "         [[4, 5, 6]]]])\n",
      "torch.Size([1, 2, 1, 3])\n",
      "==차원 제거 결과==\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([ #2*3 크기의 텐서 생성\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "print(\"==기존 텐서 출력==\")\n",
    "print(a)\n",
    "print(a.shape) \n",
    "\n",
    "print(\"==차원 추가 과정==\")\n",
    "# 첫 번째 축에 차원 추가\n",
    "a = a.unsqueeze(0)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "# 세 번째 축에 차원 추가\n",
    "a = a.unsqueeze(2)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "print(\"==차원 제거 결과==\")\n",
    "a = a.squeeze() #크기가 1인 차원을 제거한다.\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제2. 자동 미분(Autograd)    \n",
    "* x = 3.0인 텐서를 만들고 자동 미분을 활성화 (requires_grad=True)    \n",
    "* 함수 y = 3x^3 + 2x^2 + 5x 를 정의    \n",
    "* y를 x에 대해 미분하고 미분 결과를 출력    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(98.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)  # 스칼라 텐서 x를 생성하고, 자동 미분 활성화\n",
    "y=3*(x**3)+2*(x**2)+5*x #함수 정의\n",
    "y.backward() #y를 x에 대해 미분\n",
    "print(x.grad) #x=3.0에서의 미분 값 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 3. 행렬의 미분(다변수 함수)(Jacobian 행렬)\n",
    "* 2D 텐서 x = [1.0, 2.0]를 만들고 자동 미분 활성화 \n",
    "* 함수 y = [4x1 + x2^2, 3x1^2 + 2x2]를 정의\n",
    "* y를 x에 대해 미분하고 Gradient 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 2D 벡터 텐서 생성\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "\n",
    "# 벡터 함수 y 정의\n",
    "y = torch.stack([4*x[0] + x[1]**2, 3*x[0]**2 + 2*x[1]])\n",
    "\n",
    "# 벡터 미분을 위해 외부 미분 벡터 제공\n",
    "y.backward(torch.tensor([1.0, 1.0])) \n",
    "# 또는 아래와 같이 나타내도 무방함.\n",
    "# y.backward(torch.ones_like(y))  # [1.0, 1.0]과 동일한 효과\n",
    "\n",
    "# 미분 결과 (Gradient 출력)\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.tensor() -> 새로운 텐서를 정의\n",
    "* torch.stack() -> 기존 텐서들을 새로운 차원에서 쌓아올림. 즉, 입력된 텍서들을 같은 크기의 새로운 차원(axis)를 추가하여 하나의 텐서로 묶어주는 역할을 함.     \n",
    "즉, 벡터함수 y를 정의할 때 stack()을 사용해줄 수 있다. \n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 4. 신경망(Neural Network) 만들기     \n",
    "신경망은 입력층(Input Layer) -> 은닉층(Hidden Layer) -> 출력층(Output Layer)로 구성되어있으며, 각 층은 선형 변환(Linear Layer)+활성화 함수(Activation Function)조합으로 이루어져 있다. 아래의 조건을 만족하는 신경망을 만들어보자. \n",
    "* 입력 크기: 3차원 벡터\n",
    "* 은닉층: 뉴런 4개 (ReLU 활성화 함수 사용)\n",
    "* 출력층: 뉴런 2개\n",
    "* 입력값: [1.0, 2.0, 3.0]을 사용하여 출력값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망 출력:  tensor([[-0.2116,  0.0887]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn #신경망 모듈을 정의. 활성화 함수 객체를 생성해줌.\n",
    "import torch.nn.functional as F #신경망 만들 시, 활성화 '함수', 손실 '함수'를 바로 제공(객체 생성X)\n",
    "\n",
    "#신경망 클래스 정의\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNN,self).__init__()\n",
    "        self.fc1=nn.Linear(3,4) #첫번째 FC레이어(은닉층), input_dim= 3(3차원), 은닉층 뉴런 4개\n",
    "        self.fc2=nn.Linear(4,2) #두번째 FC레이어(출력층), 은닉층 뉴런 4개, 출력층 뉴런 2개개\n",
    "        #이때, nn.linear는 입력 텐서를 받을 때 자동으로 첫번째 차원을 배치 사이즈로 해석한다. \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x)) #은닉층에는 RELU 활성화함수를 사용\n",
    "        x=self.fc2(x) #출력층은 따로 함수사용하지 X, 선형변환만 이루어진다.\n",
    "        return x\n",
    "    \n",
    "model=MyNN() #모델 생성\n",
    "\n",
    "input_data=torch.tensor([[1.0,2.0,3.0]]) \n",
    "#pytorch는 기본적으로 입력 텐서에서 (batch_size, input_dim)을 기대하기 때문에, \n",
    "#1D 텐서를 사용하면 에러가 발생한다.\n",
    "#따라서 대괄호 2개 작성, batch_size=1로 해석할 것임.\n",
    "\n",
    "output=model(input_data)\n",
    "\n",
    "print(\"신경망 출력: \", output)\n",
    "#출력 차원 2임을 확인할 수 있을 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicgen2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
